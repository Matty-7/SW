\documentclass[11pt,a4paper,oneside]{report}

\usepackage{amsmath,amssymb}
\usepackage{parskip}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[a4paper,margin=1in]{geometry}
\usepackage{longtable,booktabs,array}

\usepackage{titlesec}
\titleformat{\chapter}[display]
  {\sffamily\bfseries\huge}
  {\Large \chaptertitlename\ \thechapter}
  {2ex}
  {\titlerule
  \vspace{1ex}%
  \filright\MakeUppercase}
  [\vspace{1ex}%
\titlerule]
\titleformat{\section} {\normalfont\sffamily\Large\bfseries} {\thesection}{1em}{}
\titleformat{\subsection} {\normalfont\sffamily\large\bfseries} {\thesubsection}{1em}{}
\titleformat{\subsubsection} {\normalfont\sffamily\normalsize\bfseries} {\thesubsubsection}{1em}{}
\usepackage[backend=biber, style=numeric-comp, sorting=none]{biblatex}
\addbibresource{bibfile.bib}

\usepackage[no-math]{fontspec}
\usepackage{unicode-math}
\defaultfontfeatures{Ligatures=TeX}
\setmainfont{Source Serif Pro}[BoldFont={Source Serif Pro Semibold}]
\setsansfont{SourceSansPro-Regular}[BoldFont={SourceSansPro-Semibold}]
\IfFontExistsTF{Cambria Math} {\setmathfont{Cambria Math}[Scale=1]} {\setmathfont{Asana Math}}

\usepackage{xeCJK}
\setCJKmainfont{Noto Sans SC}
\setCJKsansfont{Noto Sans SC}

\newcommand{\instructions}[1]{{\color{black}\itshape #1}}

\usepackage{upquote}
\usepackage[allcolors=blue,colorlinks=true]{hyperref}
\usepackage{xurl}
\usepackage{microtype}
\usepackage{bookmark}
\usepackage{calc}
\usepackage{etoolbox}

\usepackage{setspace}

\urlstyle{same}

\begin{document}

\onehalfspacing

% Author name (capitalized in its regular way)
\newcommand{\authorname}{Jingheng Huan}

% Title (cannot exceed three lines)
% You can insert manual linebreaks with \
\newcommand{\thetitle}{A CASE STUDY OF AI IN VISION AND SOUND GENERATION: THE EVOLUTION, APPLICATIONS, AND ETHICAL CONSIDERATIONS}

% Date of submission with normal capitalization. 
% Use the format January 29, 2022.
\newcommand{\submissiondate}{Mar 7, 2024}

% Mentor: First Name Last Name (normal capitalization)
\newcommand{\mentor}{Peng Sun}

% Academic Unit (no abbreviations)
\newcommand{\academicunit}{Division of Natural and Applied Sciences}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% DO NOT CHANGE DIRECTLY THE CONTENTS OF THE TITLE PAGE.
%% TO CUSTOMIZE THE TITLE PAGE CHANGE THE DEFINITIONS OF THE COMMANDS
%% \authorname, \thetitle, \submissiondate, \mentor, \academicunit




\begin{titlepage}

\vspace*{\bigskipamount}

\begin{center}
{\sffamily\LARGE\bfseries\MakeUppercase\thetitle\par}

\bigskip

by

\bigskip

{\Large \authorname}

\bigskip

Signature Work Product, in partial fulfillment of the \\
Duke Kunshan University Undergraduate Degree Program

\bigskip

\emph{\submissiondate}

\bigskip

Signature Work Program \\
Duke Kunshan University

\end{center}

\vfill

\textbf{\textsf{APPROVALS}}

\bigskip\bigskip\bigskip
\hrule

Mentor: \mentor, \academicunit

\bigskip\bigskip\bigskip
\hrule

Marcia B. France, Dean of Undergraduate Studies

\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Front matter
\clearpage
\pagenumbering{roman}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setcounter{tocdepth}{0} % Only top-level units (chapters) should appear in the TOC
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

% Abstract in English

\instructions{This study delves into the transformative realm of AI-driven generative technologies, 
examining their development and deployment in image and video synthesis. 
Through a comparative analysis of Generative Adversarial Networks (GANs), 
Diffusion Models, and Neural Cellular Automata, the research investigates their underlying theoretical frameworks and experimental applications. 
Key findings reveal nuanced insights into the algorithms' efficacy in generating photorealistic outputs and their potential in various industries. 
The research also critically assesses the ethical landscape, underscoring the importance of safety and fairness in AI-generated content. 
Major conclusions suggest a trajectory towards more autonomous and creative AI systems, while advocating for robust ethical guidelines to govern their use. 
This abstract, a synthesis of the comprehensive document, ensures a precise overview of the research's scope and its major contributions to the field of AI and generative media.}

\vspace{4\bigskipamount}

% Abstract in Chinese

\paragraph{\textnormal{本研究深入探讨了人工智能驱动的生成技术的变革领域，研究了这些技术在图像和视频合成中的发展和应用。
通过对生成对抗网络（GANs）、扩散模型和神经细胞自动机的比较分析，研究探讨了它们的基础理论框架和实验应用。
主要发现揭示了这些算法在生成逼真输出方面的功效及其在各行各业的潜力。
研究还对伦理环境进行了批判性评估，强调了人工智能生成内容的安全性和公平性的重要性。
主要结论表明，人工智能系统的发展轨迹将更加自主、更具创造性，同时倡导制定严格的伦理准则来规范人工智能系统的使用。
本摘要是对综合文件的综述，确保准确概述研究范围及其对人工智能和生成式媒体领域的主要贡献。}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{Acknowledgements}
\label{acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgements}

\instructions{I would like to express my sincere gratitude to my SW mentor, Prof. Peng Sun, 
for his invaluable guidance throughout this research. 
Also, I am grateful to the other members of the SW team for their support and guidance. 
In the end, I would like to thank the SW office for their support and guidance, 
and also extend my thanks to the generous funding provided by SW grants, ¥1800, which made the experiential learning part possible. 
Finally, I would like to thank my family and friends for their support and encouragement. 
}

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Add captions to your figures for them to appear in the List of Figures.
% Alternatively, comment out the next two lines if there are no tables 
% in your document.
\addcontentsline{toc}{chapter}{List of Figures}
\setcounter{tocdepth}{1}
\listoffigures\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Add captions to your tables for them to appear in the List of Tables.
% Alternatively, comment out the next two lines if there are no tables 
% in your document.
\addcontentsline{toc}{chapter}{List of Tables}
\setcounter{tocdepth}{1}
\listoftables\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Main matter

\clearpage
\pagenumbering{arabic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{introduction}

\section{Understanding of Artificial Intelligence (AI)}
\paragraph{Artificial Intelligence (AI) is an expansive field that integrates principles from computer science, mathematics, and neuroscience to forge systems capable of simulating human cognitive functions and executing tasks traditionally requiring human intellect \cite{russell2010artificial}. This interdisciplinary approach has catalyzed the transformation of AI from a mere conceptual framework into an indispensable tool across diverse sectors such as technology, finance, and entertainment. Central to AI's functionality is its ability to learn from data and make decisions autonomously, without being pre-programmed with explicit instructions. This capability has seen a dramatic surge in both application and research, evidenced by the exponential growth in scholarly publications over the last decade.
The evolution of AI is marked by significant milestones, particularly with the advent of deep learning techniques, which have revolutionized areas like computer vision and natural language processing (NLP) \cite{lecun2015deep}. Deep learning, a subset of machine learning, employs complex neural networks with multiple layers of processing units, enabling the extraction of high-level features from raw input data. This has vastly improved the performance of AI systems in tasks ranging from image and speech recognition to language translation \cite{goodfellow2016deep}.
}

\paragraph{One of the foundational models in AI's evolution is machine learning, which includes techniques for classification, regression, and clustering \cite{huang2022large}. These methods allow computers to learn patterns and make predictions from data, forming the basis for many early AI applications. As the field matured, researchers developed more sophisticated models, including neural networks, which mimic the structure and function of the human brain to perform complex pattern recognition tasks \cite{schmidhuber2015deep}.
Recent years have witnessed the emergence of specialized architectures that have further pushed the boundaries of what AI can achieve. Generative Adversarial Networks (GANs), \cite{goodfellow2014generative}, and diffusion models \cite{rombach2022high} represent the forefront of AI research in data generation. GANs, for instance, consist of two neural networks—the generator and the discriminator—competing against each other to generate new, synthetic instances of data that are indistinguishable from real data. This has proven especially powerful in the fields of vision and sound generation, enabling the creation of photorealistic images, videos, and lifelike synthetic audio \cite{granot2022drop}.
}

\paragraph{In the domain of digital content creation, these advancements have ushered in a new era of possibilities. For example, StyleGAN and its successors have demonstrated remarkable ability in generating highly realistic images, altering facial expressions in photographs, and even creating art \cite{patashnik2021styleclip}. Similarly, diffusion models have set new standards for high-fidelity image and sound generation, contributing to more immersive virtual realities and enhancing synthetic media's realism \cite{rombach2022high}.
}

\paragraph{The integration of AI in vision and sound generation not only showcases the technological marvels achievable through deep learning and neural networks but also underscores the interdisciplinary nature of AI. By drawing on insights from computer science, mathematics, and neuroscience, AI continues to evolve, breaking new ground in how machines understand and interpret the world \cite{silver2016mastering}.
}

\section{Application of AI in Image and Video Generation}
\paragraph{The integration of Artificial Intelligence (AI) within the realm of image and video generation marks a revolutionary shift, enhancing the quality and capabilities of digital media production. AI's role spans a diverse array of applications, from generating high-resolution images to real-time video enhancement, showcasing its transformative impact across multiple sectors.
}
\subsection{Generative Adversarial Networks (GANs) in Synthesizing Realistic Images}
\paragraph{Generative Adversarial Networks (GANs), a pioneering AI technology, have fundamentally transformed the landscape of digital image generation by producing visuals that are remarkably indistinguishable from reality. These networks operate on a dual-architecture system, comprising a generator that creates images and a discriminator that evaluates their authenticity, thereby facilitating a continuous improvement loop for generating increasingly realistic images. In the healthcare sector, GANs play a pivotal role by synthesizing high-fidelity medical images, aiding in the visualization of complex anatomical structures for diagnostic and educational purposes. This application not only enhances the precision of medical diagnoses but also significantly expands the resources available for medical training and research, thereby contributing to advancements in patient care \cite{granot2022drop}. Concurrently, in the realm of entertainment, GANs are instrumental in creating detailed and immersive virtual environments, revolutionizing the gaming and virtual reality industries. By generating lifelike textures and environments, GANs enable the creation of virtual worlds that offer unprecedented levels of realism, thereby elevating the user experience to new heights \cite{richter2022enhancing}. The versatility and effectiveness of GANs in synthesizing realistic images underscore their importance across diverse domains, highlighting their capacity to bridge the gap between artificial creations and real-world applications.
}
\subsection{Diffusion Models in Video Prediction and Infilling}
\paragraph{Diffusion models represent a significant advancement in the field of artificial intelligence, particularly in their application to video processing tasks, where they have demonstrated exceptional proficiency. These sophisticated models harness the power of historical data to predict future frames and infill missing segments in video sequences, a process that is crucial for creating a seamless narrative flow. By iteratively refining the generated content through a process that gradually reduces noise, diffusion models are capable of producing highly coherent and visually plausible outcomes. This ability not only enhances the realism and continuity of video footage but also offers transformative potential in the realms of video editing and post-production. Editors and filmmakers can now mend discontinuities in footage, extend narrative sequences without original content, or even generate entirely new scenes that blend indistinguishably with real footage, thereby overcoming traditional limitations imposed by incomplete or imperfect source material \cite{hoppe2022diffusion}. The application of diffusion models in these contexts underscores their pivotal role in advancing the art of video production, where the demand for high-quality, realistic content continues to grow. Their integration into video processing workflows signifies a leap forward in our ability to manipulate and enhance visual media, promising a future where the boundaries between the created and the real become increasingly blurred.
}

\subsection{Neural Cellular Automata for 3D Generation}
\paragraph{The introduction of Neural Cellular Automata (NCA) models marks a groundbreaking expansion in the capabilities of Artificial Intelligence (AI), particularly in the realm of generating three-dimensional artifacts and functional machinery. Mirroring the growth dynamics of natural systems, these models employ a set of simple, local rules that guide the evolution of cells in a discrete grid space, allowing for the emergence of complex, self-organizing structures from minimal initial states. Such a bio-inspired approach facilitates the synthesis of intricate 3D models and mechanisms, embodying both form and function, which can be further refined or evolved to meet specific design criteria. This innovative methodology has profound implications for digital manufacturing and virtual simulation, offering a novel paradigm for creating and experimenting with 3D designs in a manner that transcends the limitations of traditional CAD tools and image generation techniques. By enabling the procedural generation of objects and systems that can adapt, repair, or even replicate, Neural Cellular Automata models herald a new era in digital design and fabrication, promising to revolutionize industries ranging from aerospace to biomedical engineering \cite{sudhakaran2021growing}. This adaptive and potentially autonomous creation process not only enhances the efficiency and flexibility of design and manufacturing but also paves the way for developing more resilient and sustainable technological solutions.}

\subsection{Mitigating Biases in Generative Systems}
\paragraph{The capacity of Artificial Intelligence (AI) to transcend mere technical prowess and address pressing societal issues is exemplified in its application to bias mitigation in text-to-image generation systems. This critical area of research focuses on the development of AI algorithms capable of recognizing and rectifying biases in the content they generate, a challenge that is paramount in promoting equity and diversity within digital media landscapes. Such initiatives are driven by the imperative to dismantle systemic prejudices that may be inadvertently encoded into AI models through biased training data sets. By implementing mechanisms for the detection and correction of these biases, researchers and developers are laying the groundwork for the creation of digital environments that reflect a wide spectrum of human experiences and perspectives, thereby fostering inclusivity. This endeavor not only highlights the ethical responsibilities incumbent upon those at the forefront of AI development but also signals a shift towards more socially conscious technology practices. Efforts to engineer AI systems with the inherent ability to audit and adjust their output for bias represent a significant step forward in the pursuit of creating digital spaces that are truly representative and inclusive of all users \cite{esposito2023mitigating}. Through such advancements, AI is positioned not only as a tool for innovation but also as a catalyst for social change, challenging and reshaping our interactions with digital content in an ethically responsible manner.}

\subsection{Ethical Considerations and Deepfakes}
\paragraph{The advent of Artificial Intelligence (AI) in generating deepfakes and other manipulated media forms has precipitated a complex ethical quandary, underscoring the imperative for judicious utilization of this potent technology. Deepfakes, which are synthetic media in which a person's likeness is replaced with someone else's, leveraging advanced AI and machine learning techniques, have demonstrated the dual-edged nature of AI capabilities. While offering significant advancements in content creation, these technologies also pose substantial risks by enabling the creation of misleading or harmful content, thus blurring the lines between reality and fabrication. This paradox has catalyzed the development of sophisticated AI-driven detection systems aimed at identifying and neutralizing such manipulations to safeguard the veracity of digital media. The ethical imperative to maintain digital content integrity has led to an arms race between the creation of increasingly realistic artificial content and the countermeasures designed to detect and deter its misuse. This dynamic landscape necessitates continuous research and innovation in AI to develop robust methodologies that ensure the authenticity of digital content, thereby preserving public trust and preventing the potential for disinformation. The critical challenge lies in balancing the benefits of AI in creative and communicative expressions against the risks posed by its misuse, advocating for a regulatory and technological framework that promotes responsible AI use while protecting individuals and societies from its potential harm \cite{kasten2021layered}.}

\subsection{Computational Efficiency in Video Processing}
\paragraph{In the rapidly evolving domain of video processing, techniques such as Skip-Convolutions have emerged as groundbreaking advancements, significantly bolstering computational efficiency without sacrificing the quality of visual outputs. These innovative methods circumvent the conventional, linear processing pathways by enabling selective data transmission across layers, effectively reducing the computational load while maintaining or enhancing the fidelity of the video content. This approach is particularly advantageous for tasks requiring real-time processing capabilities, such as live streaming, augmented reality (AR) applications, and instant video communication platforms. By facilitating faster video editing and enhancement operations, Skip-Convolutions address the burgeoning demand for high-quality video content that can be produced, edited, and shared in near real-time. The integration of such techniques into video processing workflows represents a pivotal shift towards more agile and efficient content creation paradigms, ensuring that the delivery of visually rich and engaging video content keeps pace with consumer expectations and technological advancements. As a result, Skip-Convolutions not only enhance the technical capabilities of video processing software but also significantly contribute to the broader field of digital media, where speed, efficiency, and quality are paramount \cite{habibian2021skip}. This advancement underscores the continuous need for innovation in computational methodologies to meet the challenges posed by the ever-increasing demand for sophisticated video content in a variety of digital contexts.}

\section{Application of AI in Sound Generation}

\section{Current Development Trends}

The current development trends in the application of AI for image and video generation signal both depth and breadth of innovations. 
One of the most compelling trends is the movement toward high-fidelity and high-resolution image synthesis. 
Models like Latent Diffusion Models are being developed to generate high-resolution images with incredible detail [2]. 
Additionally, the advent of models like Neural Cellular Automata suggests that AI's capability is extending beyond 2D image manipulation into the realm of 3D objects and even functional machine generation [3]. 
A noteworthy trend is the focus on real-time processing and efficiency. The development of algorithms like Skip-Colutions aims to make video processing tasks faster without significant loss of quality [7]. 
Furthermore, there is a growing awareness and inclusion of ethical considerations in AI development. 
Initiatives are being taken to mitigate biases in text-to-image generative systems, and research is ongoing to find ways to prevent the malicious use of AI-generated deepfakes [5]. 
Another emerging trend is the incorporation of AI in enhancing the photorealism of generated images and videos. Advanced algorithms are now capable of augmenting computer-generated images to a level of realism that is almost indistinguishable from actual photographs [4]. 
Lastly, the domain is also seeing a trend in the unification of different techniques for a more seamless and integrated solution, 
as evident in the research towards unified keyframe propagation models [12]. 
These trends underscore the evolving nature of AI technologies in the field of image and video generation. 
The growth is not just unidimensional, focusing solely on technological advancements; rather, it is multi-faceted, 
encapsulating ethical, efficiency, and quality considerations. As AI models continue to become more sophisticated, 
these trends are expected to not only persist but to further evolve, shaping the future landscape of digital content creation. 
\section{Roadmap for Future Development}
As we navigate through the ever-evolving landscape of AI in image and video generation, it's crucial to outline a developmental roadmap that captures both the historical context and the future trajectory of AI techniques in this domain. The roadmap can be broadly categorized into the following stages: Foundational Models: The initial phase of development was marked by the emergence of foundational models like basic machine learning algorithms and neural networks. These models served as the steppingstones for more complex architectures [8]. 
Specialized Architectures: The next leap came with the introduction of specialized architectures like Generative Adversarial Networks (GANs) and Diffusion Models. These models opened up new avenues for high-quality image synthesis and video manipulation \cite{granot2022drop}. 
Ethical and Societal Considerations: As the technologies matured, the community began focusing on the ethical and societal implications of AI-generated images and videos. Efforts were geared toward mitigating biases and preventing the malicious use of AI technologies [5]. 
Efficiency and Scalability: The current stage of development emphasizes efficiency and scalability, with algorithms being optimized for real-time processing and large-scale applications [7]. 
Future Directions: Looking ahead, the focus is likely to shift toward the unification of different techniques for integrated solutions, as well as the extension of AI capabilities into areas like 3D object generation and even simulating functional machines [12]. 
As AI continues to evolve, this roadmap is expected to expand and adapt, reflecting the dynamic nature of innovations in the field of image and video generation. It serves as a guide for researchers and practitioners alike, offering a structured framework for understanding the development and potential future directions of AI technologies in this domain. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Material and Methods}
\label{material-and-methods}

\instructions{The workflow of this video-creating project is shown below:

1: Write the storyline of the video, including plots, storyboards \\
2: Collect and edit the video footage.\\
3: Use AI-generated content to create the visuals. \\
4: Edit the visuals to create the desired effect. \\
5: Post-production to clean up the video and add music and sound effects. \\
6: Publish the video on social media and other platforms. \\
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Results}
\label{results}

\instructions{Summarize the data collected in this section, and their
statistical treatment. Include only relevant data, but give sufficient
detail to justify the conclusions. It is appropriate in this section to
use equations, figures, and tables to display your data. Extensive, but
relevant data, should be reserved for an appendix where it is identified
as supporting information.}

\instructions{The table or figure must follow as closely as possible after the
paragraph in which it is referenced. Titles/captions should be kept
brief.}

\section{Examples}

Here is some inline math, $x^2 > 1$, and some display math
\begin{equation}
  \int_0^1 x^2 \, dx
\end{equation}

\begin{table}[htbp]
\centering
\begin{tabular}{@{}llll@{}}
\toprule
\emph{Replace} & \emph{With} & \emph{Your} & \emph{Table} \\
\midrule
& & & \\
& & & \\
\bottomrule
\end{tabular}
\caption{Parameters for the optimization of the principal component analysis for
olive oil adulteration.}
\label{tbl:2}
\end{table}


\begin{figure}[htbp]
\centering
\includegraphics[height=4cm]{btc.jpg}
\caption{The notorious BTC (Brandon The Cat).}
\label{fig:1}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Discussion}
\label{discussion}

\instructions{The discussion section is where you interpret and compare the
results. The objective is to point out the features and limitations of
the work. Relate your results to current knowledge in the field and to
the original purpose for undertaking the project.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusions}
\label{conclusions}

\instructions{This section is written to put the interpretation of the results
into the context of the original problem.~ Do not repeat the discussion
points or include irrelevant material. The conclusion should be based on
the evidence presented.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter*{References}
\label{references}
\addcontentsline{toc}{chapter}{References}



\printbibliography[heading=none]


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

\chapter{Additional Material}
\label{appendix-a}

This template can be viewed on Overleaf at \url{https://www.overleaf.com/read/hxjcgtkhjqcd}.
If you have an Overleaf account (either free or paid) you can copy this template to start a new Overleaf project.
If you do not want an Overleaf account you can install TeX on your computer and download the template files from Overleaf.

\end{document}